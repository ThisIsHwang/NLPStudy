## 머신러닝 흝어보기

---

데이터로부터 역으로 알고리즘을 찾기 위해 데이터를 분류 해야한다.

> 데이터의 분류
> 
1. 훈련용 데이터
    
    말 그대로, 규칙성(알고리즘)을 찾기 위해서 기계가 학습을 하기 위한 용도로 사용하는 데이터
    
2. 검증용 데이터
    
    모델의 성능을 “조절” 하기 위해 존재하는 데이터이다.
    
    어떤 관점에서 보면, 머신러닝은 기계에게 특징을 통해서 어떠한 개념을 알려주는 것으로 볼 수 있다.
    
    알려주는 과정에서 너무 과한 일반화, 혹은 너무 넓은 범위로 일반화를 하게 되면, 개념을 정확하게 이해하지 못한다.
    
3. 테스트용 데이터
    
    최종 평가를 위한 데이터, 이를 통해서 모델의 정확성을 판단한다.
    

> 분류와 회귀
> 

많은 머신러닝 문제는 분류 또는 회귀 문제에 속함.

분류와 회귀에도 또 여러가지 카테고리로 세분화 해서 분리할 수 있다.

1. 이진 분류 문제
    
    답이 이분화 되어 있는 문제, 보통 참 거짓으로 나눌 수 있는 문제이다.
    
    ex) 시험 합,불 or 정상메일,스팸메일
    
2. 다중 클래스 분류
    
    답이 이분화되어 있지 않지만, discrete한 문제
    
    ex) 5가지 카테고리의 책 분류 문제
    
3. 회귀 문제
    
    답이 discrete하지 않고, continuous 한 문제
    
    ex) 인구 밀도, 키 , 몸무게, 부동산 가격
    

> 지도 학습과 비지도 학습
> 
1. 지도 학습
    
    정답과 함께 학습하는 방식, 자연어 처리는 대부분 지도 학습에 속한다.
    
    입력값이 주어지면 입력값에 대한 답 (Label 데이터)이 주어지는 학습 방식이다.
    
2. 비지도 학습
    
    지도 학습과 다르게 정답이 없는 데이터를 비슷한 특징끼리 군집화 해서 새로운 데이터에 대한 결과를 예측하는 방식
    
3. 자기 지도 학습
    
    레이블이 
    

> 정확도 & 정밀도 & 재현율
> 
1. 정밀도
    
    정밀도란 모델이 True라고 분류한 것 중에서 실제 True인것의 비율
    
    (발언한 것 중에 진실)
    
    $$
    TP/(TP+FP)
    $$
    
2. 재현율
    
    실제 True인 것 중에서 모델이 True라고 예측한 비율
    
    (진실 중에 발언한 것)
    
    $$
    TP/(TP+FN)
    $$
    
3. 정확도
    
    전체 예측 데이터중 정답률
    
    (전체 발언중 정확한 발언)
    
    $$
    (TP+TN)/(TP+FN+FP+TN)
    $$
    

## 선형 회귀

---

> 선형 회귀 개념
> 

어떠한 변수가 데이터의 결과값에 선형적인 영향을 주어서, 이러한 선형관계를 수식(?)으로 표현해 내는 과정을 선형회귀 라고 한다.

당연하게도, 하나의 결과에는 하나의 요인만 있는 게 아닐 수 있으므로, 여러가지 요인이 있는 경우 **다중 선형 회귀 분석** 을 하고, 하나의 요인만이 존재하는 경우 **단순 선형 회귀 분석** 을 한다

> 예제
> 

공부한 시간에 따른 한 학생의 성적 결과

| hours(x) | score(y) |
| --- | --- |
| 2 | 25 |
| 3 | 50 |
| 4 | 42 |
| 5 | 61 |

이러한 결과 표가 존재할 때, 이를 공부한 시간에 따른 시험 성적을 연관지어서 선형적으로 분석하는 것을 선형 회귀라고 한다.

$$
H(x) = wx +b
$$

> 비용 함수
> 

수식 $wx +b$ 의 w값과 b 값을 찾아 내는 것이, 선형회귀의 답을 찾는 과정이고, 이를 찾아내는 방법은 여러가지가 존재한다.

여러가지 방법이라도, 전부 하나의 목적을 가지고 있는데, 그것이 **“오차를 최소화 해서 미지의 값이 들어 왔을 때, 정확히 예측하는 것”**

이다.

이러한 오차를 정의한 식을 **목적함수 또는 비용함수 또는 손실 함수**라고 한다.

$H(x) = wx +b$ 의 오차를 어떤 식으로 정의해야지 오차라고 납득이 가능할까?

선형회귀의 **평균 제곱 오차** 의 방식은 통계학의 표준편차를 구하는 방식과 상당히 유사하다.

선형함수는 직관적으로 보더라도, 1차함수이므로 직선임을 알 수 있는데, 이런 식의 직선이라면 당연히 각 테스트에 대해서 오차가 발생하게 되고, 오차는 해당 테스트 케이스의 x좌표에서의 y값 차이로 납득할 수 있다.

이러한 y값의 차이들을 단순히 더해서 모은다면, 음수 양수의 오차들이 합쳐져서 오히려 오차가 줄어드는 현상이 발생하기 때문에, 제곱을 해서 더한 후, 제곱근을 해주어서 오차를 구한다.

이러한 방식을 **평균 제곱 오차 방식**이라고 한다.